{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1.unzip dataset"
      ],
      "metadata": {
        "id": "68bwQOUvJXQo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qqb-Y99ZmW_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25efbcd8-9a34-4c5a-a664-3ff48a206dd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/Flowers-Dataset.zip, /content/Flowers-Dataset.zip.zip or /content/Flowers-Dataset.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip '/content/Flowers-Dataset.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing necessary Libraries"
      ],
      "metadata": {
        "id": "6BcqUaVY7qm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "YDOBjJ7h7qAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Activation,Dropout,Conv2D,Flatten,MaxPool2D,Reshape,InputLayer\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "s8BuWCFH9LOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Image Augmentation"
      ],
      "metadata": {
        "id": "YXsfv1hI9rXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'flowers/'"
      ],
      "metadata": {
        "id": "Ni-v3Rek9PJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_gen = ImageDataGenerator(rescale = 1./255,\n",
        "                             shear_range = 0.2,\n",
        "                             zoom_range = 0.2,\n",
        "                             horizontal_flip = True,\n",
        "                             validation_split = 0.30)\n",
        "test_data_gen = ImageDataGenerator(rescale = 1./255,validation_split = 0.30)"
      ],
      "metadata": {
        "id": "xDKm1OyW96QZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = train_data_gen.flow_from_directory(path,\n",
        "                                                 target_size=(64,64),\n",
        "                                                 batch_size=100,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True,\n",
        "                                                 color_mode='rgb',\n",
        "                                                 subset = 'training')\n",
        "\n",
        "testing_set = test_data_gen.flow_from_directory(path,\n",
        "                                                 target_size=(64,64),\n",
        "                                                 batch_size=100,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True,\n",
        "                                                 color_mode='rgb',\n",
        "                                                 subset = 'validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "g-orOH3O9-6S",
        "outputId": "0ca91a4d-fb2c-429e-b5c2-8e99b2eedb51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-e2761740de73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                  \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                  \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                                  subset = 'training')\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m testing_set = test_data_gen.flow_from_directory(path,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         interpolation=interpolation)\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m   def flow_from_dataframe(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'flowers/'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Create Model\n"
      ],
      "metadata": {
        "id": "KKwtMwL5-pmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "lJDHOcPRCgZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.Add Layers (Convolution,MaxPooling,Flatten,Dense-(Hidden Layers),Output)"
      ],
      "metadata": {
        "id": "x98mK3QBCkO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#convolution and Pooling layer 1\n",
        "model.add(Conv2D(filters=48,kernel_size=3,activation='relu',input_shape=(64,64,3)))\n",
        "model.add(MaxPool2D(pool_size=2,strides=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#convolution and Pooling layer 2\n",
        "model.add(Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=2,strides=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#Flattening the images\n",
        "model.add(Flatten())\n",
        "\n",
        "#Fully Connected layers\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(5,activation='softmax'))"
      ],
      "metadata": {
        "id": "TLwmQtSzCjCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "sMZYxR0mC3Hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.Compile The Model\n"
      ],
      "metadata": {
        "id": "bLnwrK-2DSPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "wDDyYvVbDG9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.Fit The Model"
      ],
      "metadata": {
        "id": "5foUuqvRDyF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='val_accuracy', \n",
        "                           patience=5,verbose=1,mode='auto')\n",
        "\n",
        "lr = ReduceLROnPlateau(monitor='val_accuracy', \n",
        "                       factor=0.2,patience=5, \n",
        "                       min_lr=0.00001)\n",
        "\n",
        "callback = [early_stop,lr]"
      ],
      "metadata": {
        "id": "PJN4GHwKDpBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model"
      ],
      "metadata": {
        "id": "yJsbxf-NEIgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.fit(x=training_set, validation_data=testing_set, epochs=50)"
      ],
      "metadata": {
        "id": "1A2ILadkD87l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss and Accuracy check using plot"
      ],
      "metadata": {
        "id": "QDiAF_S8G-d7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plot the loss\n",
        "plt.plot(result.history['loss'], label='train loss')\n",
        "plt.plot(result.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# plot the accuracy\n",
        "plt.plot(result.history['accuracy'], label='train acc')\n",
        "plt.plot(result.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wVteR5g5EMvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.Save the Model"
      ],
      "metadata": {
        "id": "XbQ7RpmPHI3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('flower.h5')"
      ],
      "metadata": {
        "id": "lF8o8sQUHDhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.Test The Model"
      ],
      "metadata": {
        "id": "Mx0H-7mOHdBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set.class_indices"
      ],
      "metadata": {
        "id": "j4Ga-GPjI3EW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['Daisy','Dandelion','Rose','Sunflower','Tulip'] \n",
        "def testing(img):\n",
        "    img = image.load_img(img,target_size=(64,64)) \n",
        "    x = image.img_to_array(img) \n",
        "    x = np.expand_dims(x,axis=0) \n",
        "    pred = np.argmax(model.predict(x)) \n",
        "    return print(\"Predicted class as:\",classes[pred])\n",
        "\n",
        "def img_show(img):\n",
        "    img1 = image.load_img(img,target_size=(64,64)) \n",
        "    plt.imshow(img1)"
      ],
      "metadata": {
        "id": "PaTWtDVrL-kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test1\n",
        "img_show('/content/flowers/daisy/25360380_1a881a5648.jpg')\n",
        "testing('/content/flowers/daisy/25360380_1a881a5648.jpg')"
      ],
      "metadata": {
        "id": "e0CNyj3nMBr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test2\n",
        "img_show('/content/flowers/dandelion/461632542_0387557eff.jpg')\n",
        "testing('/content/flowers/dandelion/461632542_0387557eff.jpg')"
      ],
      "metadata": {
        "id": "fkru8DsINPqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test3\n",
        "img_show('/content/flowers/rose/3753920123_c7ebc18ee3.jpg')\n",
        "testing('/content/flowers/rose/3753920123_c7ebc18ee3.jpg')"
      ],
      "metadata": {
        "id": "TUDAN5sqNta5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test4\n",
        "img_show('/content/flowers/sunflower/164670455_29d8e02bbd_n.jpg')\n",
        "testing('/content/flowers/sunflower/164670455_29d8e02bbd_n.jpg')"
      ],
      "metadata": {
        "id": "DhrLw5CrOIfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test5\n",
        "img_show('/content/flowers/tulip/3238068295_b2a7b17f48_n.jpg')\n",
        "testing('/content/flowers/tulip/3238068295_b2a7b17f48_n.jpg')"
      ],
      "metadata": {
        "id": "LxRhz-7uOivl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}